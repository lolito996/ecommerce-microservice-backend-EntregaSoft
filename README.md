# ğŸ“‹ DocumentaciÃ³n TÃ©cnica del Proyecto E-Commerce Microservices

## ğŸ“‘ Tabla de Contenidos

1. [IntroducciÃ³n](#introducciÃ³n)
2. [Arquitectura del Sistema](#arquitectura-del-sistema)
3. [Microservicios Implementados](#microservicios-implementados)
4. [Stack TecnolÃ³gico](#stack-tecnolÃ³gico)
5. [Estrategia CI/CD](#estrategia-cicd)
6. [Estrategia de Testing](#estrategia-de-testing)
7. [AnÃ¡lisis de MÃ©tricas de Rendimiento](#anÃ¡lisis-de-mÃ©tricas-de-rendimiento)
8. [Oportunidades de Mejora](#oportunidades-de-mejora)
9. [Diagramas de Arquitectura](#diagramas-de-arquitectura)

---

## ğŸ¯ IntroducciÃ³n

### DescripciÃ³n del Proyecto

Este proyecto es una **plataforma de e-commerce backend** construida bajo una arquitectura de **microservicios** utilizando **Spring Boot** y **Spring Cloud**. El sistema estÃ¡ diseÃ±ado para ser escalable, resiliente y mantenible, siguiendo las mejores prÃ¡cticas de desarrollo de software empresarial.

### Objetivos del Proyecto

- **Escalabilidad Horizontal**: Cada microservicio puede escalarse independientemente segÃºn la demanda
- **Alta Disponibilidad**: Sistema resiliente con circuit breakers y health checks
- **Despliegue Continuo**: AutomatizaciÃ³n completa de CI/CD con Jenkins y GitHub Actions
- **Observabilidad**: Monitoreo, tracing distribuido y mÃ©tricas de rendimiento
- **Desacoplamiento**: Servicios independientes que se comunican mediante APIs REST

### Estado del Proyecto

âœ… **Implementado y Funcional**
- 11 microservicios core operativos
- Pipeline CI/CD completo (Jenkins + GitHub Actions)
- Tests unitarios, E2E y de rendimiento
- Despliegue automatizado en Kubernetes (Kind)
- Monitoreo con Zipkin y Prometheus

---

## ğŸ—ï¸ Arquitectura del Sistema

### PatrÃ³n ArquitectÃ³nico

El proyecto implementa una **arquitectura de microservicios** con los siguientes componentes principales:

1. **Service Discovery (Eureka)**: Registro y descubrimiento de servicios
2. **API Gateway (Spring Cloud Gateway)**: Punto de entrada Ãºnico para todas las peticiones
3. **Cloud Config Server**: CentralizaciÃ³n de configuraciÃ³n
4. **Distributed Tracing (Zipkin)**: Trazabilidad de requests a travÃ©s de servicios
5. **Circuit Breaker (Resilience4j)**: Resiliencia ante fallos

### Flujo de ComunicaciÃ³n

```
Cliente â†’ API Gateway â†’ Service Discovery â†’ Microservicios â†’ Bases de Datos
                â†“
            Zipkin (Tracing)
                â†“
         Prometheus (MÃ©tricas)
```

### Principios de DiseÃ±o Aplicados

- **Single Responsibility**: Cada servicio tiene una responsabilidad especÃ­fica
- **API-First**: ComunicaciÃ³n mediante APIs REST bien definidas
- **Stateless**: Los servicios no mantienen estado de sesiÃ³n
- **Database per Service**: Cada servicio tiene su propia base de datos
- **Event-Driven**: ComunicaciÃ³n asÃ­ncrona cuando es necesario

---

## ğŸ”§ Microservicios Implementados

### 1. **Service Discovery** (Puerto 8761)
- **TecnologÃ­a**: Spring Cloud Eureka Server
- **FunciÃ³n**: Registro centralizado de todos los microservicios
- **CaracterÃ­sticas**:
  - Auto-registro de servicios
  - Health checks automÃ¡ticos
  - Dashboard de visualizaciÃ³n
- **RazÃ³n de ImplementaciÃ³n**: Permite que los servicios se descubran dinÃ¡micamente sin configuraciÃ³n hardcodeada

### 2. **Cloud Config Server** (Puerto 9296)
- **TecnologÃ­a**: Spring Cloud Config Server
- **FunciÃ³n**: GestiÃ³n centralizada de configuraciÃ³n
- **CaracterÃ­sticas**:
  - ConfiguraciÃ³n por ambiente (dev, staging, prod)
  - ActualizaciÃ³n dinÃ¡mica sin reiniciar servicios
- **RazÃ³n de ImplementaciÃ³n**: Centraliza la configuraciÃ³n, facilitando el mantenimiento y la gestiÃ³n de mÃºltiples ambientes

### 3. **API Gateway** (Puerto 8080)
- **TecnologÃ­a**: Spring Cloud Gateway
- **FunciÃ³n**: Punto de entrada Ãºnico para todas las peticiones
- **CaracterÃ­sticas**:
  - Enrutamiento dinÃ¡mico basado en rutas
  - Load balancing automÃ¡tico
  - CORS configurado
  - Circuit breaker integration
- **RazÃ³n de ImplementaciÃ³n**: Simplifica el acceso del cliente, centraliza la seguridad y facilita el monitoreo

### 4. **User Service** (Puerto 8700)
- **FunciÃ³n**: GestiÃ³n de usuarios y autenticaciÃ³n
- **Endpoints principales**:
  - `POST /user-service/api/users` - Crear usuario
  - `GET /user-service/api/users/{id}` - Obtener usuario
  - `PUT /user-service/api/users/{id}` - Actualizar usuario
- **RazÃ³n de ImplementaciÃ³n**: Separa la lÃ³gica de usuarios del resto del sistema, permitiendo escalabilidad independiente

### 5. **Product Service** (Puerto 8500)
- **FunciÃ³n**: CatÃ¡logo de productos
- **Endpoints principales**:
  - `GET /product-service/api/products` - Listar productos
  - `POST /product-service/api/products` - Crear producto
  - `GET /product-service/api/products/{id}` - Obtener producto
- **RazÃ³n de ImplementaciÃ³n**: Servicio mÃ¡s consultado, requiere alta disponibilidad y escalabilidad

### 6. **Order Service** (Puerto 8300)
- **FunciÃ³n**: GestiÃ³n de Ã³rdenes
- **Endpoints principales**:
  - `POST /order-service/api/orders` - Crear orden
  - `GET /order-service/api/orders` - Listar Ã³rdenes
  - `GET /order-service/api/orders/{id}` - Obtener orden
- **RazÃ³n de ImplementaciÃ³n**: Core del negocio, requiere transaccionalidad y consistencia

### 7. **Shipping Service** (Puerto 8600)
- **FunciÃ³n**: GestiÃ³n de envÃ­os y tracking
- **Endpoints principales**:
  - `POST /shipping-service/api/shippings` - Crear envÃ­o
  - `GET /shipping-service/api/shippings` - Listar envÃ­os
- **RazÃ³n de ImplementaciÃ³n**: Servicio independiente que puede escalarse segÃºn demanda logÃ­stica

### 8. **Payment Service** (Puerto 8400)
- **FunciÃ³n**: Procesamiento de pagos
- **Endpoints principales**:
  - `POST /payment-service/api/payments` - Procesar pago
  - `GET /payment-service/api/payments/{id}` - Obtener estado de pago
- **RazÃ³n de ImplementaciÃ³n**: Servicio crÃ­tico que requiere seguridad y aislamiento

### 9. **Favourite Service** (Puerto 8800)
- **FunciÃ³n**: GestiÃ³n de favoritos del usuario
- **Endpoints principales**:
  - `POST /favourite-service/api/favourites` - Agregar favorito
  - `GET /favourite-service/api/favourites/{userId}` - Listar favoritos
- **RazÃ³n de ImplementaciÃ³n**: Funcionalidad independiente que puede optimizarse por separado

### 10. **Proxy Client** (Puerto 8900)
- **FunciÃ³n**: Cliente frontend proxy
- **CaracterÃ­sticas**: Interfaz para aplicaciÃ³n frontend
- **RazÃ³n de ImplementaciÃ³n**: Facilita la comunicaciÃ³n entre el frontend y los microservicios

### 11. **Zipkin** (Puerto 9411)
- **TecnologÃ­a**: Distributed Tracing System
- **FunciÃ³n**: Trazabilidad distribuida de requests
- **RazÃ³n de ImplementaciÃ³n**: Permite diagnosticar problemas de rendimiento y latencia en sistemas distribuidos

---

## ğŸ’» Stack TecnolÃ³gico

### Backend
- **Java 11**: Lenguaje de programaciÃ³n
- **Spring Boot 2.5.7**: Framework principal
- **Spring Cloud 2020.0.4**: Microservicios y cloud-native features
- **Spring Data JPA**: Persistencia de datos
- **Resilience4j**: Circuit breaker y resiliencia
- **Spring Cloud Sleuth**: Distributed tracing
- **SpringDoc OpenAPI**: DocumentaciÃ³n de APIs

### Infraestructura
- **Docker**: ContainerizaciÃ³n
- **Kubernetes (Kind)**: OrquestaciÃ³n de contenedores
- **Maven**: GestiÃ³n de dependencias y build
- **Eureka**: Service discovery
- **Zipkin**: Distributed tracing
- **Prometheus**: MÃ©tricas y monitoreo

### CI/CD
- **Jenkins**: Pipeline de CI/CD principal
- **GitHub Actions**: CI/CD para workflows especÃ­ficos
- **Docker Hub**: Registro de imÃ¡genes
- **Kubectl**: GestiÃ³n de Kubernetes

### Testing
- **JUnit 5**: Framework de testing
- **Mockito**: Mocking de dependencias
- **TestContainers**: Testing con contenedores reales
- **WireMock**: Mocking de servicios externos
- **Locust**: Testing de rendimiento

### Bases de Datos
- **MySQL/PostgreSQL**: Bases de datos relacionales por servicio
- **Flyway**: Migraciones de base de datos

---

## ğŸš€ Estrategia CI/CD

### Pipeline Dual: Jenkins + GitHub Actions

El proyecto implementa una estrategia hÃ­brida de CI/CD para maximizar la flexibilidad y cobertura:

#### **Jenkins Pipeline** (Principal)

**UbicaciÃ³n**: `Jenkinsfile`

**CaracterÃ­sticas**:
- Pipeline completo de CI/CD
- DetecciÃ³n automÃ¡tica de cambios por servicio
- Build paralelo de servicios modificados
- Despliegue automÃ¡tico a staging/producciÃ³n
- Tests E2E y de rendimiento

**Etapas del Pipeline**:
1. **Checkout & Detect Changes**: Identifica servicios modificados
2. **Build Core Services**: Construye service-discovery y api-gateway
3. **Build & Test Changed Services**: Compila y ejecuta tests unitarios
4. **Docker Build**: Construye imÃ¡genes Docker
5. **Docker Push**: Sube imÃ¡genes a Docker Hub
6. **Deploy Core Services**: Despliega servicios core a staging
7. **Deploy to Staging**: Despliega servicios modificados
8. **Integration Tests**: Ejecuta tests de integraciÃ³n
9. **Deploy Services for Testing**: Despliega todos los servicios
10. **E2E Tests**: Pruebas end-to-end
11. **Performance Tests**: Pruebas de rendimiento con Locust
12. **Deploy to Production**: Despliegue a producciÃ³n (condicional)

**Variables de Entorno**:
- `REGISTRY`: `docker.io/gersondj`
- `K8S_NAMESPACE_STAGING`: `microservices-staging`
- `K8S_NAMESPACE_PROD`: `microservices-prod`

#### **GitHub Actions** (Complementario)

**UbicaciÃ³n**: `.github/workflows/`

**Workflows Implementados**:

1. **Unit Tests Workflows** (30 archivos)
   - `*-pipeline-*-push.yml`: Ejecuta tests unitarios en push
   - `*-pipeline-*-pr.yml`: Ejecuta tests unitarios en pull requests
   - **Servicios**: api-gateway, cloud-config, user-service, product-service, order-service, shipping-service, payment-service, favourite-service, proxy-client, service-discovery
   - **Branches**: develop, stage, master

2. **E2E Tests Workflow** (`e2e-tests.yml`)
   - Crea cluster Kind temporal
   - Construye y despliega todos los servicios
   - Ejecuta pruebas end-to-end
   - Limpia recursos al finalizar

3. **Performance Tests Workflow** (`performance-tests.yml`)
   - Crea cluster Kind temporal
   - Despliega servicios
   - Ejecuta tests de rendimiento con Locust
   - Genera reportes HTML y CSV

**Ventajas de la Estrategia Dual**:
- âœ… **Jenkins**: Pipeline completo, control granular, integraciÃ³n con infraestructura propia
- âœ… **GitHub Actions**: Tests rÃ¡pidos, feedback inmediato, integraciÃ³n nativa con GitHub
- âœ… **Redundancia**: Si un sistema falla, el otro puede continuar

---

## ğŸ§ª Estrategia de Testing

### PirÃ¡mide de Testing

El proyecto implementa una **pirÃ¡mide de testing completa** con mÃºltiples niveles:

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  E2E Tests      â”‚  â† Pocos, crÃ­ticos
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Integration Tests     â”‚  â† Algunos, importantes
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      Unit Tests                       â”‚  â† Muchos, rÃ¡pidos
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1. **Unit Tests** (Tests Unitarios)

**Framework**: JUnit 5 + Mockito + AssertJ

**Cobertura**:
- Tests por servicio en `src/test/java/`
- ValidaciÃ³n de lÃ³gica de negocio
- Mocking de dependencias externas
- ValidaciÃ³n de DTOs y entidades

**EjecuciÃ³n**:
- **GitHub Actions**: AutomÃ¡tico en cada push/PR
- **Jenkins**: Durante la etapa "Build & Test Changed Services"
- **Comando**: `mvn test`

**ConfiguraciÃ³n**:
```xml
<plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-surefire-plugin</artifactId>
    <configuration>
        <includes>
            <include>**/*Test.java</include>
            <include>**/*Tests.java</include>
        </includes>
        <excludes>
            <exclude>**/*IntegrationTest.java</exclude>
        </excludes>
    </configuration>
</plugin>
```

**Ejemplo de Test**:
```java
@Test
@DisplayName("Should create user successfully")
void testCreateUser() {
    // Arrange
    UserDto userDto = new UserDto(...);
    
    // Act
    UserDto result = userService.create(userDto);
    
    // Assert
    assertThat(result).isNotNull();
    assertThat(result.getUserId()).isNotNull();
}
```

**RazÃ³n de ImplementaciÃ³n**: Validar rÃ¡pidamente la lÃ³gica de negocio antes de integraciones mÃ¡s complejas.

---

### 2. **Integration Tests** (Tests de IntegraciÃ³n)

**Framework**: TestContainers + WireMock + Spring Boot Test

**Cobertura**:
- ComunicaciÃ³n entre servicios
- IntegraciÃ³n con bases de datos reales
- ValidaciÃ³n de APIs REST
- SimulaciÃ³n de servicios externos con WireMock

**Ejemplo**: `OrderPaymentServiceIntegrationTest`
- Prueba la comunicaciÃ³n entre Order Service y Payment Service
- Utiliza WireMock para simular respuestas del Payment Service
- Valida flujos transaccionales completos

**EjecuciÃ³n**:
- **Jenkins**: Etapa "Integration Tests"
- **GitHub Actions**: Workflow `integration-tests.yml`

**CaracterÃ­sticas**:
- Utiliza TestContainers para bases de datos reales
- Aislamiento mediante transacciones
- ValidaciÃ³n de contratos entre servicios

**RazÃ³n de ImplementaciÃ³n**: Asegurar que los servicios se comunican correctamente y que las integraciones funcionan como se espera.

---

### 3. **E2E Tests** (End-to-End Tests)

**Framework**: curl + bash scripts + validaciÃ³n de respuestas HTTP

**Cobertura**:
- Flujos completos de usuario
- ValidaciÃ³n de escenarios de negocio end-to-end
- Pruebas en ambiente staging real

**Escenarios Testeados**:

1. **User Registration and Profile Update Flow**
   ```bash
   # Crear usuario
   POST /user-service/api/users
   # Validar respuesta
   # Actualizar usuario
   PUT /user-service/api/users/{id}
   ```

2. **Product Catalog and Order Creation Flow**
   ```bash
   # Listar productos
   GET /product-service/api/products
   # Crear orden
   POST /order-service/api/orders
   # Agregar items a orden
   POST /shipping-service/api/shippings
   ```

3. **Order Processing Flow**
   ```bash
   # Crear orden
   POST /order-service/api/orders
   # Procesar pago
   POST /payment-service/api/payments
   # Verificar estado
   GET /order-service/api/orders/{id}
   ```

**EjecuciÃ³n**:
- **Jenkins**: Etapa "E2E Tests" despuÃ©s del despliegue a staging
- **GitHub Actions**: Workflow `e2e-tests.yml` con cluster Kind temporal

**Ambiente**:
- ClÃºster Kubernetes (Kind) con todos los servicios desplegados
- API Gateway expuesto vÃ­a port-forward o NodePort
- ValidaciÃ³n de respuestas HTTP y cÃ³digos de estado

**RazÃ³n de ImplementaciÃ³n**: Validar que todo el sistema funciona correctamente en conjunto, simulando el comportamiento real del usuario.

---

### 4. **Performance Tests** (Tests de Rendimiento)

**Framework**: Locust (Python)

**ConfiguraciÃ³n**:
- **Archivo**: `locustfile.py`
- **Usuarios simulados**: 50
- **Spawn rate**: 10 usuarios/segundo
- **DuraciÃ³n**: 300 segundos (5 minutos)
- **Host**: API Gateway (localhost:30080)

**Comportamiento Simulado**:

La clase `EcommerceUser` simula el comportamiento de un usuario real:

```python
class EcommerceUser(HttpUser):
    wait_time = between(1, 3)  # Espera entre 1-3 segundos
    
    @task(3)  # Peso 3 (27.3% probabilidad)
    def view_products(self):
        """Ver catÃ¡logo de productos"""
        
    @task(2)  # Peso 2 (18.2% probabilidad)
    def create_user(self):
        """Crear nuevo usuario"""
        
    @task(2)  # Peso 2 (18.2% probabilidad)
    def get_user(self):
        """Obtener detalles de usuario"""
        
    @task(1)  # Peso 1 (9.1% probabilidad cada uno)
    def create_order(self):
        """Crear orden"""
        
    @task(1)
    def add_order_item(self):
        """Agregar item a orden"""
        
    @task(1)
    def view_orders(self):
        """Ver Ã³rdenes"""
        
    @task(1)
    def view_order_items(self):
        """Ver items de orden"""
```

**DistribuciÃ³n de Tareas**:
- **viewProducts**: 27.3% (mÃ¡s frecuente)
- **createUser**: 18.2%
- **getUser**: 18.2%
- **createOrder**: 9.1%
- **addOrderItem**: 9.1%
- **viewOrders**: 9.1%
- **viewOrderItems**: 9.1%

**EjecuciÃ³n**:
- **Jenkins**: Etapa "Performance Tests"
- **GitHub Actions**: Workflow `performance-tests.yml`
- **Reportes**: HTML y CSV generados automÃ¡ticamente

**RazÃ³n de ImplementaciÃ³n**: Identificar cuellos de botella, validar capacidad del sistema y asegurar que el rendimiento es aceptable bajo carga.

---

## ğŸ“Š AnÃ¡lisis de MÃ©tricas de Rendimiento

### Reporte de Locust - EjecuciÃ³n del 3/11/2025

**PerÃ­odo**: 3/11/2025, 1:16:11 p.m. - 1:21:11 p.m. (5 minutos)
**Target Host**: http://localhost:30080
**Script**: locustfile.py

---

### ğŸ“ˆ Resumen Ejecutivo

| MÃ©trica | Valor | InterpretaciÃ³n |
|---------|-------|----------------|
| **Total Requests** | 7,202 | âœ… Excelente volumen de pruebas |
| **Failed Requests** | 0 | âœ… **100% de Ã©xito - Sin errores** |
| **Average Response Time** | 26.52 ms | âœ… Excelente (objetivo < 100ms) |
| **RPS (Requests Per Second)** | 24.06 | âœ… Buena tasa de procesamiento |
| **P95 Response Time** | 51 ms | âœ… Muy bueno (objetivo < 200ms) |
| **P99 Response Time** | 330 ms | âš ï¸ Aceptable (objetivo < 500ms) |
| **Max Response Time** | 6,189 ms | âš ï¸ Requiere atenciÃ³n (picos ocasionales) |

**Veredicto General**: âœ… **Sistema funcionando correctamente bajo carga**

---

### ğŸ“‹ EstadÃ­sticas por Endpoint

#### 1. **GET /product-service/api/products**
- **Requests**: 2,019 (28% del total)
- **Fails**: 0
- **Average**: 28.74 ms
- **Min/Max**: 3 ms / 4,336 ms
- **P95**: 36 ms
- **P99**: 180 ms
- **RPS**: 6.74
- **TamaÃ±o promedio**: 1,055 bytes

**AnÃ¡lisis**:
- âœ… **Endpoint mÃ¡s consultado** - Refleja el comportamiento real (catÃ¡logo de productos)
- âœ… **Rendimiento excelente** en el 95% de los casos (36ms)
- âš ï¸ **Picos ocasionales** hasta 4.3 segundos - Posible conexiÃ³n a BD o cache miss
- âœ… **Sin errores** - 100% de disponibilidad

**RecomendaciÃ³n**: Implementar cache (Redis) para reducir latencia y picos.

---

#### 2. **POST /user-service/api/users**
- **Requests**: 1,284 (18% del total)
- **Fails**: 0
- **Average**: 18.71 ms
- **Min/Max**: 4 ms / 3,294 ms
- **P95**: 39 ms
- **P99**: 150 ms
- **RPS**: 4.29
- **TamaÃ±o promedio**: 473 bytes

**AnÃ¡lisis**:
- âœ… **Rendimiento muy bueno** - Operaciones de escritura rÃ¡pidas
- âœ… **P95 excelente** (39ms) - El 95% de las respuestas son muy rÃ¡pidas
- âš ï¸ **Picos ocasionales** hasta 3.3 segundos - Posible validaciÃ³n de duplicados o escritura en BD
- âœ… **Sin errores** - Sistema robusto

**RecomendaciÃ³n**: Optimizar consultas de validaciÃ³n (Ã­ndices, cache de validaciones).

---

#### 3. **GET /user-service/api/users/4**
- **Requests**: 1,285 (18% del total)
- **Fails**: 0
- **Average**: 8.81 ms
- **Min/Max**: 3 ms / 469 ms
- **P95**: 20 ms
- **P99**: 59 ms
- **RPS**: 4.29
- **TamaÃ±o promedio**: 510 bytes

**AnÃ¡lisis**:
- âœ… **Rendimiento excepcional** - Lecturas muy rÃ¡pidas
- âœ… **P95 excelente** (20ms) - Consultas simples optimizadas
- âœ… **Consistencia** - Menor variabilidad que otros endpoints
- âœ… **Sin errores**

**RecomendaciÃ³n**: Mantener este nivel de rendimiento. Considerar cache para usuarios frecuentes.

---

#### 4. **GET /shipping-service/api/shippings**
- **Requests**: 695 (10% del total)
- **Fails**: 0
- **Average**: 97.44 ms âš ï¸
- **Min/Max**: 17 ms / 6,189 ms
- **P95**: 340 ms
- **P99**: 1,300 ms
- **RPS**: 2.32
- **TamaÃ±o promedio**: 2,040 bytes

**AnÃ¡lisis**:
- âš ï¸ **Endpoint mÃ¡s lento** - Requiere optimizaciÃ³n
- âš ï¸ **Alta variabilidad** - P95 de 340ms y mÃ¡ximo de 6.2 segundos
- âš ï¸ **Posible cuello de botella** - Consultas complejas o joins
- âœ… **Sin errores** - Sistema funcional pero lento

**RecomendaciÃ³n**: 
- **URGENTE**: Revisar queries SQL, agregar Ã­ndices
- Implementar paginaciÃ³n si no existe
- Considerar cache para consultas frecuentes
- Revisar relaciones con otras tablas (joins)

---

#### 5. **POST /order-service/api/orders**
- **Requests**: 636 (9% del total)
- **Fails**: 0
- **Average**: 11.34 ms
- **Min/Max**: 3 ms / 497 ms
- **P95**: 40 ms
- **P99**: 94 ms
- **RPS**: 2.12
- **TamaÃ±o promedio**: 164 bytes

**AnÃ¡lisis**:
- âœ… **Rendimiento excelente** - Operaciones de escritura rÃ¡pidas
- âœ… **P95 muy bueno** (40ms) - Transacciones eficientes
- âœ… **Consistencia** - Baja variabilidad
- âœ… **Sin errores**

**RecomendaciÃ³n**: Mantener este nivel. Considerar optimizaciÃ³n de transacciones si se aumenta la complejidad.

---

#### 6. **GET /order-service/api/orders**
- **Requests**: 668 (9% del total)
- **Fails**: 0
- **Average**: 25.24 ms
- **Min/Max**: 4 ms / 3,529 ms
- **P95**: 32 ms
- **P99**: 360 ms
- **RPS**: 2.23
- **TamaÃ±o promedio**: 798 bytes

**AnÃ¡lisis**:
- âœ… **Rendimiento bueno** - Lecturas eficientes
- âœ… **P95 excelente** (32ms) - Consultas optimizadas
- âš ï¸ **Picos ocasionales** hasta 3.5 segundos - Posible crecimiento de datos
- âœ… **Sin errores**

**RecomendaciÃ³n**: Implementar paginaciÃ³n si no existe. Monitorear crecimiento de datos.

---

#### 7. **POST /shipping-service/api/shippings**
- **Requests**: 615 (9% del total)
- **Fails**: 0
- **Average**: 9.53 ms
- **Min/Max**: 4 ms / 237 ms
- **P95**: 25 ms
- **P99**: 61 ms
- **RPS**: 2.05
- **TamaÃ±o promedio**: 327 bytes

**AnÃ¡lisis**:
- âœ… **Rendimiento excelente** - Operaciones de escritura muy rÃ¡pidas
- âœ… **P95 muy bueno** (25ms) - Inserciones eficientes
- âœ… **Consistencia** - Baja variabilidad
- âœ… **Sin errores**

**RecomendaciÃ³n**: Mantener este nivel de rendimiento.

---

### ğŸ“Š AnÃ¡lisis de Percentiles (Response Time Statistics)

#### Percentiles Agregados (Todos los Endpoints)

| Percentil | Tiempo (ms) | InterpretaciÃ³n |
|-----------|-------------|----------------|
| **50% (Mediana)** | 6 ms | âœ… Excelente - La mitad de las requests son instantÃ¡neas |
| **60%** | 7 ms | âœ… Muy bueno |
| **70%** | 8 ms | âœ… Muy bueno |
| **80%** | 12 ms | âœ… Excelente |
| **90%** | 29 ms | âœ… Muy bueno |
| **95%** | 51 ms | âœ… Excelente (objetivo < 200ms) |
| **99%** | 330 ms | âš ï¸ Aceptable (objetivo < 500ms) |
| **100% (MÃ¡ximo)** | 6,189 ms | âš ï¸ Requiere atenciÃ³n (picos ocasionales) |

**InterpretaciÃ³n**:
- âœ… **95% de las requests** se completan en menos de 51ms - Excelente
- âœ… **99% de las requests** se completan en menos de 330ms - Aceptable
- âš ï¸ **1% de las requests** pueden tardar hasta 6 segundos - Requiere investigaciÃ³n

**ConclusiÃ³n**: El sistema es **muy rÃ¡pido en la mayorÃ­a de los casos**, pero tiene **picos ocasionales** que deben investigarse.

---

### ğŸ¯ DistribuciÃ³n de Carga

#### Ratio Per Class (DistribuciÃ³n de Tareas)

| Tarea | Porcentaje | Requests Estimados |
|-------|------------|-------------------|
| **viewProducts** | 27.3% | ~1,965 |
| **createUser** | 18.2% | ~1,310 |
| **getUser** | 18.2% | ~1,310 |
| **createOrder** | 9.1% | ~655 |
| **addOrderItem** | 9.1% | ~655 |
| **viewOrders** | 9.1% | ~655 |
| **viewOrderItems** | 9.1% | ~655 |

**AnÃ¡lisis**:
- âœ… **DistribuciÃ³n realista** - Los usuarios consultan productos mÃ¡s frecuentemente
- âœ… **Balance adecuado** - Mezcla de lecturas y escrituras
- âœ… **Escenario realista** - Refleja comportamiento de usuario real

---

### ğŸ¯ MÃ©tricas Clave de Rendimiento

#### 1. **Throughput (RPS - Requests Per Second)**
- **Total RPS**: 24.06 requests/segundo
- **InterpretaciÃ³n**: El sistema puede procesar ~24 requests simultÃ¡neas por segundo
- **Capacidad**: Con 50 usuarios concurrentes, cada usuario hace ~0.48 requests/segundo (muy realista)

#### 2. **Tasa de Error**
- **Failed Requests**: 0 de 7,202
- **Tasa de Error**: 0%
- **InterpretaciÃ³n**: âœ… **Sistema 100% disponible** durante la prueba

#### 3. **Latencia Promedio**
- **Average**: 26.52 ms
- **InterpretaciÃ³n**: âœ… **Excelente** - Respuestas en menos de 30ms en promedio

#### 4. **Consistencia (P95/P99)**
- **P95**: 51 ms (excelente)
- **P99**: 330 ms (aceptable)
- **InterpretaciÃ³n**: El sistema es **consistente** en el 95% de los casos, con **variabilidad aceptable** en el 99%

---

### ğŸ” AnÃ¡lisis de Picos de Latencia

#### Endpoints con Mayor Variabilidad

1. **GET /shipping-service/api/shippings**
   - MÃ¡ximo: 6,189 ms
   - **Causa probable**: Consultas complejas, joins, falta de Ã­ndices
   - **Impacto**: Alto (afecta experiencia de usuario)

2. **GET /product-service/api/products**
   - MÃ¡ximo: 4,336 ms
   - **Causa probable**: Consultas sin cache, paginaciÃ³n ineficiente
   - **Impacto**: Medio (endpoint muy usado)

3. **GET /order-service/api/orders**
   - MÃ¡ximo: 3,529 ms
   - **Causa probable**: Crecimiento de datos, falta de paginaciÃ³n
   - **Impacto**: Medio

**Recomendaciones**:
1. **Implementar cache** (Redis) para endpoints frecuentes
2. **Optimizar queries SQL** - Agregar Ã­ndices, revisar joins
3. **Implementar paginaciÃ³n** si no existe
4. **Monitorear crecimiento de datos** - Considerar particionamiento

---

### âœ… Conclusiones del AnÃ¡lisis

#### Fortalezas del Sistema

1. âœ… **100% de disponibilidad** - Sin errores durante la prueba
2. âœ… **Rendimiento excelente** en el 95% de los casos
3. âœ… **Latencia promedio muy baja** (26.52 ms)
4. âœ… **Throughput adecuado** (24 RPS)
5. âœ… **Sistema estable** bajo carga de 50 usuarios concurrentes

#### Ãreas de Mejora

1. âš ï¸ **GET /shipping-service/api/shippings** - Requiere optimizaciÃ³n urgente
2. âš ï¸ **Picos ocasionales** - Investigar causas (BD, cache, red)
3. âš ï¸ **P99 puede mejorarse** - Reducir de 330ms a <200ms

#### MÃ©tricas Objetivo

| MÃ©trica | Actual | Objetivo | Estado |
|---------|--------|----------|--------|
| **Failed Requests** | 0% | < 0.1% | âœ… Superado |
| **Average Response Time** | 26.52 ms | < 100 ms | âœ… Superado |
| **P95 Response Time** | 51 ms | < 200 ms | âœ… Superado |
| **P99 Response Time** | 330 ms | < 500 ms | âœ… Cumplido |
| **Max Response Time** | 6,189 ms | < 1,000 ms | âŒ Requiere mejora |

---

## ğŸš€ Oportunidades de Mejora

### 1. **Performance y Escalabilidad** ğŸ”¥ ALTA PRIORIDAD

#### 1.1 Implementar Cache (Redis)
- **Problema**: Endpoints como `/product-service/api/products` tienen picos de latencia
- **SoluciÃ³n**: Implementar Redis para cache de productos, usuarios y Ã³rdenes frecuentes
- **Impacto**: ReducciÃ³n de latencia del 50-80% en endpoints frecuentes
- **Esfuerzo**: Medio (2-3 semanas)

#### 1.2 Optimizar Queries SQL
- **Problema**: `GET /shipping-service/api/shippings` tiene latencia alta (P95: 340ms)
- **SoluciÃ³n**: 
  - Agregar Ã­ndices en columnas frecuentemente consultadas
  - Optimizar joins complejos
  - Implementar paginaciÃ³n eficiente
- **Impacto**: ReducciÃ³n de latencia del 60-70% en endpoints lentos
- **Esfuerzo**: Bajo-Medio (1-2 semanas)

#### 1.3 Implementar Connection Pooling
- **Problema**: Posible saturaciÃ³n de conexiones a BD
- **SoluciÃ³n**: Configurar HikariCP con pool optimizado
- **Impacto**: Mejora de throughput y estabilidad
- **Esfuerzo**: Bajo (3-5 dÃ­as)

---

### 2. **Observabilidad y Monitoreo** ğŸ”¥ ALTA PRIORIDAD

#### 2.1 Dashboard de MÃ©tricas (Grafana)
- **Problema**: No hay visualizaciÃ³n centralizada de mÃ©tricas
- **SoluciÃ³n**: Implementar Grafana con Prometheus
- **Impacto**: Visibilidad completa del sistema
- **Esfuerzo**: Medio (1-2 semanas)

#### 2.2 Alertas AutomÃ¡ticas
- **Problema**: No hay alertas proactivas de problemas
- **SoluciÃ³n**: Configurar alertas en Prometheus/Alertmanager
- **MÃ©tricas clave**:
  - Tasa de error > 1%
  - Latencia P95 > 200ms
  - Disponibilidad < 99.9%
- **Impacto**: DetecciÃ³n temprana de problemas
- **Esfuerzo**: Bajo-Medio (1 semana)

#### 2.3 Logging Centralizado (ELK Stack)
- **Problema**: Logs distribuidos en mÃºltiples servicios
- **SoluciÃ³n**: Implementar ELK (Elasticsearch, Logstash, Kibana)
- **Impacto**: BÃºsqueda y anÃ¡lisis de logs centralizado
- **Esfuerzo**: Medio (2 semanas)

---

### 3. **Seguridad** ğŸ”¥ ALTA PRIORIDAD

#### 3.1 AutenticaciÃ³n y AutorizaciÃ³n (OAuth2/JWT)
- **Problema**: No hay autenticaciÃ³n implementada
- **SoluciÃ³n**: Implementar OAuth2 con JWT tokens
- **Impacto**: Seguridad de endpoints y datos
- **Esfuerzo**: Alto (3-4 semanas)

#### 3.2 Rate Limiting
- **Problema**: Vulnerable a ataques DDoS
- **SoluciÃ³n**: Implementar rate limiting en API Gateway
- **Impacto**: ProtecciÃ³n contra abuso
- **Esfuerzo**: Bajo (3-5 dÃ­as)

#### 3.3 HTTPS/TLS
- **Problema**: ComunicaciÃ³n sin cifrado
- **SoluciÃ³n**: Implementar certificados TLS
- **Impacto**: Seguridad de datos en trÃ¡nsito
- **Esfuerzo**: Medio (1 semana)

---

### 4. **Resiliencia y Alta Disponibilidad** âš ï¸ MEDIA PRIORIDAD

#### 4.1 Implementar Retry Logic
- **Problema**: Fallos transitorios pueden causar errores
- **SoluciÃ³n**: Implementar retry con exponential backoff
- **Impacto**: Mayor resiliencia ante fallos temporales
- **Esfuerzo**: Bajo-Medio (1 semana)

#### 4.2 Health Checks Avanzados
- **Problema**: Health checks bÃ¡sicos pueden no detectar problemas reales
- **SoluciÃ³n**: Implementar health checks que validen dependencias (BD, servicios externos)
- **Impacto**: DetecciÃ³n temprana de problemas
- **Esfuerzo**: Bajo (3-5 dÃ­as)

#### 4.3 Auto-scaling Horizontal
- **Problema**: Escalado manual no es eficiente
- **SoluciÃ³n**: Implementar HPA (Horizontal Pod Autoscaler) en Kubernetes
- **Impacto**: Escalado automÃ¡tico segÃºn carga
- **Esfuerzo**: Medio (1-2 semanas)

---

### 5. **Testing** âš ï¸ MEDIA PRIORIDAD

#### 5.1 Aumentar Cobertura de Unit Tests
- **Problema**: Cobertura actual desconocida
- **SoluciÃ³n**: 
  - Aumentar cobertura a >80%
  - Implementar JaCoCo para mÃ©tricas
- **Impacto**: Mayor confianza en cambios
- **Esfuerzo**: Alto (continuo)

#### 5.2 Tests de Carga Avanzados
- **Problema**: Tests de rendimiento bÃ¡sicos
- **SoluciÃ³n**: 
  - Implementar escenarios mÃ¡s complejos
  - Tests de estrÃ©s (spike testing)
  - Tests de resistencia (soak testing)
- **Impacto**: Mejor preparaciÃ³n para producciÃ³n
- **Esfuerzo**: Medio (2 semanas)

#### 5.3 Contract Testing
- **Problema**: No hay validaciÃ³n de contratos entre servicios
- **SoluciÃ³n**: Implementar Spring Cloud Contract
- **Impacto**: PrevenciÃ³n de breaking changes
- **Esfuerzo**: Medio (2 semanas)

---

### 6. **CI/CD** âš ï¸ MEDIA PRIORIDAD

#### 6.1 Implementar Canary Deployments
- **Problema**: Despliegues directos pueden causar problemas
- **SoluciÃ³n**: Implementar canary deployments en Kubernetes
- **Impacto**: ReducciÃ³n de riesgo en despliegues
- **Esfuerzo**: Alto (3-4 semanas)

#### 6.2 Blue-Green Deployments
- **Problema**: Downtime durante despliegues
- **SoluciÃ³n**: Implementar blue-green deployments
- **Impacto**: Cero downtime en despliegues
- **Esfuerzo**: Alto (3-4 semanas)

#### 6.3 Automated Rollback
- **Problema**: Rollback manual es lento
- **SoluciÃ³n**: Implementar rollback automÃ¡tico basado en mÃ©tricas
- **Impacto**: RecuperaciÃ³n rÃ¡pida ante problemas
- **Esfuerzo**: Medio (2 semanas)

---

### 7. **Arquitectura** âš ï¸ MEDIA PRIORIDAD

#### 7.1 Event-Driven Architecture
- **Problema**: ComunicaciÃ³n sÃ­ncrona puede causar acoplamiento
- **SoluciÃ³n**: Implementar mensajerÃ­a (RabbitMQ/Kafka) para eventos
- **Impacto**: Mayor desacoplamiento y escalabilidad
- **Esfuerzo**: Alto (4-6 semanas)

#### 7.2 API Versioning
- **Problema**: No hay versionado de APIs
- **SoluciÃ³n**: Implementar versionado en URLs o headers
- **Impacto**: Compatibilidad con versiones anteriores
- **Esfuerzo**: Medio (2 semanas)

#### 7.3 CQRS (Command Query Responsibility Segregation)
- **Problema**: Modelos de lectura y escritura mezclados
- **SoluciÃ³n**: Separar modelos de lectura y escritura
- **Impacto**: OptimizaciÃ³n independiente de lecturas y escrituras
- **Esfuerzo**: Alto (6-8 semanas)

---

### 8. **DocumentaciÃ³n** ğŸ“ BAJA PRIORIDAD

#### 8.1 DocumentaciÃ³n de APIs (OpenAPI/Swagger)
- **Problema**: DocumentaciÃ³n bÃ¡sica
- **SoluciÃ³n**: Mejorar documentaciÃ³n OpenAPI con ejemplos
- **Impacto**: Facilita integraciÃ³n para desarrolladores
- **Esfuerzo**: Bajo (1 semana)

#### 8.2 Runbooks Operacionales
- **Problema**: No hay guÃ­as de operaciÃ³n
- **SoluciÃ³n**: Crear runbooks para operaciones comunes
- **Impacto**: Facilita troubleshooting
- **Esfuerzo**: Bajo (1 semana)

---

## ğŸ“ Diagramas de Arquitectura

### 1. Arquitectura General del Sistema

```mermaid
graph TB
    subgraph "Cliente"
        Web[Web Browser]
        Mobile[Mobile App]
    end
    
    subgraph "API Gateway Layer"
        Gateway[API Gateway<br/>Spring Cloud Gateway<br/>:8080]
    end
    
    subgraph "Service Discovery"
        Eureka[Eureka Server<br/>:8761]
    end
    
    subgraph "Config & Monitoring"
        Config[Cloud Config Server<br/>:9296]
        Zipkin[Zipkin<br/>:9411]
        Prometheus[Prometheus]
    end
    
    subgraph "Business Services"
        User[User Service<br/>:8700]
        Product[Product Service<br/>:8500]
        Order[Order Service<br/>:8300]
        Shipping[Shipping Service<br/>:8600]
        Payment[Payment Service<br/>:8400]
        Favourite[Favourite Service<br/>:8800]
        Proxy[Proxy Client<br/>:8900]
    end
    
    subgraph "Data Layer"
        DB1[(User DB<br/>MySQL)]
        DB2[(Product DB<br/>MySQL)]
        DB3[(Order DB<br/>MySQL)]
        DB4[(Shipping DB<br/>MySQL)]
        DB5[(Payment DB<br/>MySQL)]
        DB6[(Favourite DB<br/>MySQL)]
    end
    
    Web --> Gateway
    Mobile --> Gateway
    Gateway --> Eureka
    Gateway --> User
    Gateway --> Product
    Gateway --> Order
    Gateway --> Shipping
    Gateway --> Payment
    Gateway --> Favourite
    Gateway --> Proxy
    
    User --> Eureka
    Product --> Eureka
    Order --> Eureka
    Shipping --> Eureka
    Payment --> Eureka
    Favourite --> Eureka
    Proxy --> Eureka
    
    User --> Config
    Product --> Config
    Order --> Config
    Shipping --> Config
    Payment --> Config
    
    User --> Zipkin
    Product --> Zipkin
    Order --> Zipkin
    Shipping --> Zipkin
    
    User --> DB1
    Product --> DB2
    Order --> DB3
    Shipping --> DB4
    Payment --> DB5
    Favourite --> DB6
    
    User --> Prometheus
    Product --> Prometheus
    Order --> Prometheus
```

---

### 2. Flujo de CI/CD (Jenkins + GitHub Actions)

```mermaid
graph LR
    subgraph "Source Control"
        Git[Git Repository<br/>GitHub]
    end
    
    subgraph "CI/CD Tools"
        Jenkins[Jenkins Pipeline]
        GHA[GitHub Actions]
    end
    
    subgraph "Build & Test"
        Build[Maven Build]
        Unit[Unit Tests]
        Int[Integration Tests]
        E2E[E2E Tests]
        Perf[Performance Tests]
    end
    
    subgraph "Container Registry"
        DockerHub[Docker Hub<br/>gersondj/*]
    end
    
    subgraph "Kubernetes"
        Staging[Staging Cluster<br/>Kind]
        Prod[Production Cluster<br/>Kind]
    end
    
    Git --> Jenkins
    Git --> GHA
    
    Jenkins --> Build
    GHA --> Build
    
    Build --> Unit
    Unit --> Int
    Int --> E2E
    E2E --> Perf
    
    Build --> DockerHub
    DockerHub --> Staging
    Staging --> Prod
```

---

### 3. Flujo de Request End-to-End

```mermaid
sequenceDiagram
    participant Client
    participant Gateway as API Gateway
    participant Eureka as Service Discovery
    participant Product as Product Service
    participant Order as Order Service
    participant Shipping as Shipping Service
    participant Zipkin as Zipkin
    participant DB as Database
    
    Client->>Gateway: GET /product-service/api/products
    Gateway->>Eureka: Discover Product Service
    Eureka-->>Gateway: Product Service Location
    Gateway->>Product: Forward Request
    Product->>DB: Query Products
    DB-->>Product: Products Data
    Product->>Zipkin: Send Trace
    Product-->>Gateway: Response
    Gateway-->>Client: Response
    
    Client->>Gateway: POST /order-service/api/orders
    Gateway->>Order: Forward Request
    Order->>DB: Create Order
    DB-->>Order: Order Created
    Order->>Shipping: Create Shipping
    Shipping->>DB: Create Shipping Record
    DB-->>Shipping: Shipping Created
    Shipping->>Zipkin: Send Trace
    Shipping-->>Order: Shipping Created
    Order->>Zipkin: Send Trace
    Order-->>Gateway: Response
    Gateway-->>Client: Response
```

---

### 4. Arquitectura de Testing

```mermaid
graph TB
    subgraph "Testing Pyramid"
        E2E[E2E Tests<br/>Locust + curl<br/>Real Environment]
        Int[Integration Tests<br/>TestContainers<br/>WireMock]
        Unit[Unit Tests<br/>JUnit 5<br/>Mockito]
    end
    
    subgraph "CI/CD Integration"
        Jenkins[Jenkins Pipeline]
        GHA[GitHub Actions]
    end
    
    subgraph "Test Environments"
        Kind[Kind Cluster<br/>Kubernetes]
        Local[Local Docker]
    end
    
    Unit --> Jenkins
    Unit --> GHA
    Int --> Jenkins
    Int --> GHA
    E2E --> Jenkins
    E2E --> GHA
    
    E2E --> Kind
    Int --> Local
    Unit --> Local
```

---

### 5. Arquitectura de Monitoreo y Observabilidad

```mermaid
graph TB
    subgraph "Application Services"
        Services[Microservices]
    end
    
    subgraph "Tracing"
        Zipkin[Zipkin<br/>Distributed Tracing]
    end
    
    subgraph "Metrics"
        Prometheus[Prometheus<br/>Metrics Collection]
        Grafana[Grafana<br/>Dashboards]
    end
    
    subgraph "Logging"
        ELK[ELK Stack<br/>Elasticsearch<br/>Logstash<br/>Kibana]
    end
    
    subgraph "Alerting"
        AlertManager[Alertmanager]
    end
    
    Services --> Zipkin
    Services --> Prometheus
    Services --> ELK
    
    Prometheus --> Grafana
    Prometheus --> AlertManager
    
    AlertManager --> |Alerts| Teams[Teams/Slack]
```

---

## ğŸ“ Resumen Ejecutivo

### Estado Actual

âœ… **Sistema Funcional y Estable**
- 11 microservicios operativos
- 100% de disponibilidad en tests de rendimiento
- Latencia promedio excelente (26.52 ms)
- Pipeline CI/CD completo y funcional

### MÃ©tricas Clave

| MÃ©trica | Valor | Estado |
|---------|-------|--------|
| **Disponibilidad** | 100% | âœ… Excelente |
| **Latencia Promedio** | 26.52 ms | âœ… Excelente |
| **P95 Latency** | 51 ms | âœ… Excelente |
| **P99 Latency** | 330 ms | âœ… Aceptable |
| **Throughput** | 24.06 RPS | âœ… Adecuado |
| **Tasa de Error** | 0% | âœ… Perfecto |

### PrÃ³ximos Pasos Recomendados

1. **Corto Plazo (1-2 meses)**
   - Implementar cache (Redis)
   - Optimizar queries SQL en Shipping Service
   - Implementar autenticaciÃ³n (OAuth2/JWT)
   - Dashboard de mÃ©tricas (Grafana)

2. **Medio Plazo (3-6 meses)**
   - Event-driven architecture
   - Canary deployments
   - Logging centralizado (ELK)
   - Aumentar cobertura de tests

3. **Largo Plazo (6-12 meses)**
   - CQRS implementation
   - Auto-scaling avanzado
   - Multi-region deployment
   - Advanced monitoring y alerting

---

## ğŸ“š Referencias

- **Spring Boot Documentation**: https://spring.io/projects/spring-boot
- **Spring Cloud Documentation**: https://spring.io/projects/spring-cloud
- **Kubernetes Documentation**: https://kubernetes.io/docs/
- **Locust Documentation**: https://docs.locust.io/
- **Jenkins Pipeline Documentation**: https://www.jenkins.io/doc/book/pipeline/

---

**Documento generado el**: 3 de noviembre de 2025
**VersiÃ³n del Proyecto**: 0.1.0
**Ãšltima actualizaciÃ³n**: Basado en ejecuciÃ³n de performance tests del 3/11/2025

